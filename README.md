# Projet: E1 - Collecte de Donn√©es

## 1. Description G√©n√©rale

Ce projet centralise plusieurs processus de collecte et de gestion de donn√©es provenant de sources vari√©es. Il inclut des scripts pour l'extraction de donn√©es depuis des bases de donn√©es, des fichiers Parquet, l'API Twitter, ainsi qu'une API pour manipuler les donn√©es collect√©es.

## 2. Installation Globale

Toutes les d√©pendances Python pour les diff√©rents sous-projets sont g√©r√©es dans un unique fichier √† la racine. Pour les installer, ex√©cutez :

```bash
pip install -r requirements.txt
```

Assurez-vous de vous r√©f√©rer au `README.md` de chaque sous-dossier pour la configuration sp√©cifique (ex: cl√©s d'API, variables d'environnement).

## 3. Structure du Projet

Le projet est divis√© en plusieurs modules, chacun avec sa propre documentation d√©taill√©e.

### üìÅ `c1-extract_data/`

*   **R√¥le :** Contient un ensemble de scripts pour des extractions de donn√©es g√©n√©rales (ex: depuis des bases de donn√©es, fichiers CSV/Parquet, Azure).
*   **Documentation :** [./c1-extract_data/README.md](./c1-extract_data/README.md)

### üìÅ `c1-twitter-api-extract-data/`

*   **R√¥le :** Un pipeline d√©di√© √† la collecte de tweets mentionnant Leroy Merlin, √† leur nettoyage et √† leur stockage dans une base de donn√©es SQLite.
*   **Documentation :** [./c1-twitter-api-extract-data/README.md](./c1-twitter-api-extract-data/README.md)

### üìÅ `c5-api_crud/`

*   **R√¥le :** Une API (FastAPI) qui expose des points de terminaison CRUD pour g√©rer les avis clients stock√©s sur Google BigQuery.
*   **Documentation :** [./c5-api_crud/README.md](./c5-api_crud/README.md)

## 4. Automatisation

Certaines t√¢ches de collecte de donn√©es sont automatis√©es via un script central situ√© dans `c1-extract_data/cron/automate_all_extractions.sh`. Ce script est con√ßu pour √™tre ex√©cut√© par une t√¢che cron syst√®me.
